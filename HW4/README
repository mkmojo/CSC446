Name:   {Qiyuan Qiu}
Email:  {qqiu@cs.rochester.edu}
Course: {CSC446}
Homework: {

Implement perceptron for the voting dataset using Python. Split the 435 examples into 348 train / 45
dev / 42 test and report your classification accuracy on the test set.

}

******** Files ********
{
    hw4.py      : The source code.
    Makefile    : Makefile for this assignment.
    voting2.dat : Data used for this assignment.
    README      : This document.
}

******** Algorithm ********
{
    Parse data into three sections, the train, dev and test set.
    Train the perceptron model.
        Augment data set with ones col.
        Repeat for 1000 times:
            Iterating through data points
                if current prediction is wrong:
                    W <-- W + cnt_err_contribution  (Equation 4.55, Bishop)
                else:
                    W <-- W
                Evaluate Ep
    Adjust the model on dev set.
    Do the test on test set.
}

******** Instructions ********
{
    to run the homework please type the following command:
    make
}

******** Results ********
{
    For 10,000 iterations,
    The final W for the perceptron model is: [[-6. -3.  1. -5.  4. -3.  5.  0. -9.  2. -7.  5.  0.  3. -4. -1.]]

    The final accuracy on test data set is:  0.880952380952
}

******** Interpretation ********
{
    Based on the result I got from experiments. The dataset we have is not linearly 
    separatable. Therefore I ran 10,000 iterations to train the perceptron model.
    As the result, the accuracy fluctuates if we chose different iterations.

    Compared with linear regression, this method is easier to code. However, because 
    the accuracy fluctuates and we have no idea if this model is just slow to converge
    or it will never converge. 

}

******** References ********
{
    Any external materials you used for the homework. Anyone you discussed with
}
